{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4058699c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching chunk: 2024-06-30T23:00Z to 2024-07-14T22:30Z\n",
      "Fetching chunk: 2024-07-14T22:30Z to 2024-07-28T22:00Z\n",
      "Fetching chunk: 2024-07-28T22:00Z to 2024-08-11T21:30Z\n",
      "Fetching chunk: 2024-08-11T21:30Z to 2024-08-25T21:00Z\n",
      "Fetching chunk: 2024-08-25T21:00Z to 2024-09-08T20:30Z\n",
      "Fetching chunk: 2024-09-08T20:30Z to 2024-09-22T20:00Z\n",
      "Fetching chunk: 2024-09-22T20:00Z to 2024-10-06T19:30Z\n",
      "Fetching chunk: 2024-10-06T19:30Z to 2024-10-20T19:00Z\n",
      "Fetching chunk: 2024-10-20T19:00Z to 2024-11-03T18:30Z\n",
      "Fetching chunk: 2024-11-03T18:30Z to 2024-11-17T18:00Z\n",
      "Fetching chunk: 2024-11-17T18:00Z to 2024-12-01T17:30Z\n",
      "Fetching chunk: 2024-12-01T17:30Z to 2024-12-15T17:00Z\n",
      "Fetching chunk: 2024-12-15T17:00Z to 2024-12-29T16:30Z\n",
      "Fetching chunk: 2024-12-29T16:30Z to 2025-01-12T16:00Z\n",
      "Fetching chunk: 2025-01-12T16:00Z to 2025-01-26T15:30Z\n",
      "Fetching chunk: 2025-01-26T15:30Z to 2025-02-09T15:00Z\n",
      "Fetching chunk: 2025-02-09T15:00Z to 2025-02-23T14:30Z\n",
      "Fetching chunk: 2025-02-23T14:30Z to 2025-03-09T14:00Z\n",
      "Fetching chunk: 2025-03-09T14:00Z to 2025-03-23T13:30Z\n",
      "Fetching chunk: 2025-03-23T13:30Z to 2025-04-06T13:00Z\n",
      "Fetching chunk: 2025-04-06T13:00Z to 2025-04-20T12:30Z\n",
      "Fetching chunk: 2025-04-20T12:30Z to 2025-05-04T12:00Z\n",
      "Fetching chunk: 2025-05-04T12:00Z to 2025-05-18T11:30Z\n",
      "Fetching chunk: 2025-05-18T11:30Z to 2025-06-01T11:00Z\n",
      "Fetching chunk: 2025-06-01T11:00Z to 2025-06-15T10:30Z\n",
      "Fetching chunk: 2025-06-15T10:30Z to 2025-06-29T10:00Z\n",
      "Fetching chunk: 2025-06-29T10:00Z to 2025-06-30T23:00Z\n",
      "Saved combined CSV to: C:\\Users\\spice\\Dropbox\\Documents\\Imperial 2024.2025\\MECH70038 - Research Projects\\_My Thesis\\Data\\carbon_intensity_with_mix_2024-06-30_to_2025-06-30.csv\n"
     ]
    }
   ],
   "source": [
    "#Time given is UTC. \n",
    "#This pulls the national actual and forecast emission factors. Intensity has a 14 day limit. So will need to batch over longer periods.\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "start_date_str = \"2024-06-30T23:00Z\"\n",
    "end_date_str   = \"2025-06-30T23:00Z\"  # example range > 14 days\n",
    "\n",
    "folder = r\"C:\\Users\\spice\\Dropbox\\Documents\\Imperial 2024.2025\\MECH70038 - Research Projects\\_My Thesis\\Data\"\n",
    "file_out = fr\"{folder}\\carbon_intensity_with_mix_{start_date_str[:10]}_to_{end_date_str[:10]}.csv\"\n",
    "\n",
    "headers = {\"Accept\": \"application/json\"}\n",
    "max_window = timedelta(days=13, hours=23, minutes=30)\n",
    "\n",
    "# === DATE PARSING ===\n",
    "def parse_utc(datestr):\n",
    "    return datetime.strptime(datestr, \"%Y-%m-%dT%H:%MZ\")\n",
    "\n",
    "start_dt = parse_utc(start_date_str)\n",
    "end_dt   = parse_utc(end_date_str)\n",
    "\n",
    "# === STORAGE ===\n",
    "intensity_rows = []\n",
    "generation_rows = []\n",
    "\n",
    "# === LOOP OVER CHUNKS ===\n",
    "curr_start = start_dt\n",
    "while curr_start < end_dt:\n",
    "    curr_end = min(curr_start + max_window, end_dt)\n",
    "    from_str = curr_start.strftime(\"%Y-%m-%dT%H:%MZ\")\n",
    "    to_str   = curr_end.strftime(\"%Y-%m-%dT%H:%MZ\")\n",
    "\n",
    "    print(f\"Fetching chunk: {from_str} to {to_str}\")\n",
    "\n",
    "    # === INTENSITY API ===\n",
    "    int_url = f\"https://api.carbonintensity.org.uk/intensity/{from_str}/{to_str}\"\n",
    "    int_resp = requests.get(int_url, headers=headers)\n",
    "    int_resp.raise_for_status()\n",
    "    for item in int_resp.json()[\"data\"]:\n",
    "        intensity_rows.append({\n",
    "            \"from\": item[\"from\"],\n",
    "            \"to\": item[\"to\"],\n",
    "            \"forecast\": item[\"intensity\"].get(\"forecast\"),\n",
    "            \"actual\": item[\"intensity\"].get(\"actual\"),\n",
    "            \"index\": item[\"intensity\"].get(\"index\")\n",
    "        })\n",
    "\n",
    "    # === GENERATION MIX API ===\n",
    "    mix_url = f\"https://api.carbonintensity.org.uk/generation/{from_str}/{to_str}\"\n",
    "    mix_resp = requests.get(mix_url, headers=headers)\n",
    "    mix_resp.raise_for_status()\n",
    "    for item in mix_resp.json()[\"data\"]:\n",
    "        row = {\"from\": item[\"from\"], \"to\": item[\"to\"]}\n",
    "        for fuel in item[\"generationmix\"]:\n",
    "            row[fuel[\"fuel\"]] = fuel[\"perc\"]\n",
    "        generation_rows.append(row)\n",
    "\n",
    "    curr_start = curr_end\n",
    "\n",
    "# === CONVERT TO DATAFRAMES ===\n",
    "intensity_df = pd.DataFrame(intensity_rows).drop_duplicates(subset=[\"from\", \"to\"])\n",
    "generation_df = pd.DataFrame(generation_rows).drop_duplicates(subset=[\"from\", \"to\"])\n",
    "\n",
    "# === MERGE AND SAVE ===\n",
    "merged_df = intensity_df.merge(generation_df, on=[\"from\", \"to\"], how=\"left\")\n",
    "merged_df.to_csv(file_out, index=False)\n",
    "print(f\"Saved combined CSV to: {file_out}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sef-python-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
