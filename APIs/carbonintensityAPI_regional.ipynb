{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56ce2d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 2024-06-30T23:00Z to 2024-07-14T22:30Z...\n",
      "Fetching 2024-07-14T22:30Z to 2024-07-28T22:00Z...\n",
      "Fetching 2024-07-28T22:00Z to 2024-08-11T21:30Z...\n",
      "Fetching 2024-08-11T21:30Z to 2024-08-25T21:00Z...\n",
      "Fetching 2024-08-25T21:00Z to 2024-09-08T20:30Z...\n",
      "Fetching 2024-09-08T20:30Z to 2024-09-22T20:00Z...\n",
      "Fetching 2024-09-22T20:00Z to 2024-10-06T19:30Z...\n",
      "Fetching 2024-10-06T19:30Z to 2024-10-20T19:00Z...\n",
      "Fetching 2024-10-20T19:00Z to 2024-11-03T18:30Z...\n",
      "Fetching 2024-11-03T18:30Z to 2024-11-17T18:00Z...\n",
      "Fetching 2024-11-17T18:00Z to 2024-12-01T17:30Z...\n",
      "Fetching 2024-12-01T17:30Z to 2024-12-15T17:00Z...\n",
      "Fetching 2024-12-15T17:00Z to 2024-12-29T16:30Z...\n",
      "Fetching 2024-12-29T16:30Z to 2025-01-12T16:00Z...\n",
      "Fetching 2025-01-12T16:00Z to 2025-01-26T15:30Z...\n",
      "Fetching 2025-01-26T15:30Z to 2025-02-09T15:00Z...\n",
      "Fetching 2025-02-09T15:00Z to 2025-02-23T14:30Z...\n",
      "Fetching 2025-02-23T14:30Z to 2025-03-09T14:00Z...\n",
      "Fetching 2025-03-09T14:00Z to 2025-03-23T13:30Z...\n",
      "Fetching 2025-03-23T13:30Z to 2025-04-06T13:00Z...\n",
      "Fetching 2025-04-06T13:00Z to 2025-04-20T12:30Z...\n",
      "Fetching 2025-04-20T12:30Z to 2025-05-04T12:00Z...\n",
      "Fetching 2025-05-04T12:00Z to 2025-05-18T11:30Z...\n",
      "Fetching 2025-05-18T11:30Z to 2025-06-01T11:00Z...\n",
      "Fetching 2025-06-01T11:00Z to 2025-06-15T10:30Z...\n",
      "Fetching 2025-06-15T10:30Z to 2025-06-29T10:00Z...\n",
      "Fetching 2025-06-29T10:00Z to 2025-06-30T23:00Z...\n",
      "Saved named-region forecast matrix to: C:\\Users\\spice\\Dropbox\\Documents\\Imperial 2024.2025\\MECH70038 - Research Projects\\_My Thesis\\Data\\regional_forecast_matrix_named_2024-06-30_to_2025-06-30.csv\n"
     ]
    }
   ],
   "source": [
    "#This version of the code is simpler, just pulling regional forecast data over the period without the generation mix\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "start_datetime_str = \"2024-06-30T23:00Z\"\n",
    "end_datetime_str   = \"2025-06-30T23:00Z\"\n",
    "\n",
    "output_dir = r\"C:\\Users\\spice\\Dropbox\\Documents\\Imperial 2024.2025\\MECH70038 - Research Projects\\_My Thesis\\Data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_filename = f\"regional_forecast_matrix_named_{start_datetime_str[:10]}_to_{end_datetime_str[:10]}.csv\"\n",
    "output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "headers = {'Accept': 'application/json'}\n",
    "\n",
    "# === PARSE DATES ===\n",
    "def parse_utc(datestr):\n",
    "    return datetime.strptime(datestr, \"%Y-%m-%dT%H:%MZ\")\n",
    "\n",
    "start_dt = parse_utc(start_datetime_str)\n",
    "end_dt   = parse_utc(end_datetime_str)\n",
    "max_window = timedelta(days=13, hours=23, minutes=30)\n",
    "\n",
    "# === INITIALISE STRUCTURES ===\n",
    "forecast_data = {}  # key: (from, dnoregion), value: forecast\n",
    "all_regions = set()\n",
    "\n",
    "# === LOOP OVER API CHUNKS ===\n",
    "curr_start = start_dt\n",
    "while curr_start < end_dt:\n",
    "    curr_end = min(curr_start + max_window, end_dt)\n",
    "    from_str = curr_start.strftime(\"%Y-%m-%dT%H:%MZ\")\n",
    "    to_str   = curr_end.strftime(\"%Y-%m-%dT%H:%MZ\")\n",
    "\n",
    "    print(f\"Fetching {from_str} to {to_str}...\")\n",
    "    url = f\"https://api.carbonintensity.org.uk/regional/intensity/{from_str}/{to_str}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    timeblocks = response.json()[\"data\"]\n",
    "\n",
    "    for block in timeblocks:\n",
    "        timestamp = block[\"from\"]\n",
    "        for region in block.get(\"regions\", []):\n",
    "            region_name = region.get(\"dnoregion\")\n",
    "            all_regions.add(region_name)\n",
    "            forecast = region.get(\"intensity\", {}).get(\"forecast\")\n",
    "            forecast_data[(timestamp, region_name)] = forecast\n",
    "\n",
    "    curr_start = curr_end\n",
    "\n",
    "# === GENERATE FULL TIME RANGE ===\n",
    "full_times = []\n",
    "dt = start_dt\n",
    "while dt < end_dt:\n",
    "    from_str = dt.strftime(\"%Y-%m-%dT%H:%MZ\")\n",
    "    to_str   = (dt + timedelta(minutes=30)).strftime(\"%Y-%m-%dT%H:%MZ\")\n",
    "    full_times.append((from_str, to_str))\n",
    "    dt += timedelta(minutes=30)\n",
    "\n",
    "# === BUILD FINAL ROWS ===\n",
    "sorted_regions = sorted(all_regions)\n",
    "fieldnames = [\"from\", \"to\"] + sorted_regions\n",
    "all_rows = []\n",
    "\n",
    "for from_str, to_str in full_times:\n",
    "    row = {\"from\": from_str, \"to\": to_str}\n",
    "    for region in sorted_regions:\n",
    "        row[region] = forecast_data.get((from_str, region), \"\")\n",
    "    all_rows.append(row)\n",
    "\n",
    "# === WRITE TO CSV ===\n",
    "with open(output_path, mode=\"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(all_rows)\n",
    "\n",
    "print(f\"Saved named-region forecast matrix to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da12e04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching 2025-01-01T00:00Z to 2025-01-14T23:30Z...\n",
      "Fetching 2025-01-14T23:30Z to 2025-01-16T00:00Z...\n",
      "Saved combined CSV to: C:\\Users\\spice\\Dropbox\\Documents\\Imperial 2024.2025\\MECH70038 - Research Projects\\_My Thesis\\Data\\regional_forecast_2025-01-01_to_2025-01-16.csv\n"
     ]
    }
   ],
   "source": [
    "#Time given is UTC. \n",
    "#This pulls the regional forecast emission factors and generation. Intensity has a 14 day limit. So batches over longer periods.\n",
    "#Sometimes model data unavailable - this code keeps all settlement periods and just adds blank rows if data unavailable\n",
    "import requests\n",
    "import csv\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "start_datetime_str = \"2025-01-01T00:00Z\"\n",
    "end_datetime_str   = \"2025-01-16T00:00Z\"\n",
    "\n",
    "output_dir = r\"C:\\Users\\spice\\Dropbox\\Documents\\Imperial 2024.2025\\MECH70038 - Research Projects\\_My Thesis\\Data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_filename = f\"regional_forecast_{start_datetime_str[:10]}_to_{end_datetime_str[:10]}.csv\"\n",
    "output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "headers = {'Accept': 'application/json'}\n",
    "\n",
    "# === PARSE DATES ===\n",
    "def parse_utc(datestr):\n",
    "    return datetime.strptime(datestr, \"%Y-%m-%dT%H:%MZ\")\n",
    "\n",
    "start_dt = parse_utc(start_datetime_str)\n",
    "end_dt   = parse_utc(end_datetime_str)\n",
    "max_window = timedelta(days=13, hours=23, minutes=30)\n",
    "\n",
    "# === INITIALISE STRUCTURE ===\n",
    "raw_data = {}  # key: (from, regionid), value: row dict\n",
    "all_fuels = set()\n",
    "all_regionids = set()\n",
    "\n",
    "# === LOOP OVER CHUNKS ===\n",
    "curr_start = start_dt\n",
    "while curr_start < end_dt:\n",
    "    curr_end = min(curr_start + max_window, end_dt)\n",
    "    from_str = curr_start.strftime(\"%Y-%m-%dT%H:%MZ\")\n",
    "    to_str   = curr_end.strftime(\"%Y-%m-%dT%H:%MZ\")\n",
    "\n",
    "    print(f\"Fetching {from_str} to {to_str}...\")\n",
    "    url = f\"https://api.carbonintensity.org.uk/regional/intensity/{from_str}/{to_str}\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    timeblocks = response.json()[\"data\"]\n",
    "\n",
    "    for block in timeblocks:\n",
    "        timestamp = block[\"from\"]\n",
    "        timestamp_to = block[\"to\"]\n",
    "        for region in block.get(\"regions\", []):\n",
    "            regionid = region[\"regionid\"]\n",
    "            all_regionids.add(regionid)\n",
    "\n",
    "            row = {\n",
    "                \"from\": timestamp,\n",
    "                \"to\": timestamp_to,\n",
    "                \"regionid\": regionid,\n",
    "                \"dnoregion\": region.get(\"dnoregion\"),\n",
    "                \"forecast\": region.get(\"intensity\", {}).get(\"forecast\"),\n",
    "                \"index\": region.get(\"intensity\", {}).get(\"index\")\n",
    "            }\n",
    "\n",
    "            for fuel_data in region.get(\"generationmix\", []):\n",
    "                fuel = fuel_data[\"fuel\"]\n",
    "                row[fuel] = fuel_data[\"perc\"]\n",
    "                all_fuels.add(fuel)\n",
    "\n",
    "            raw_data[(timestamp, regionid)] = row\n",
    "\n",
    "    curr_start = curr_end\n",
    "\n",
    "# === GENERATE FULL TIME RANGE ===\n",
    "full_times = []\n",
    "dt = start_dt\n",
    "while dt < end_dt:\n",
    "    from_str = dt.strftime(\"%Y-%m-%dT%H:%MZ\")\n",
    "    to_str   = (dt + timedelta(minutes=30)).strftime(\"%Y-%m-%dT%H:%MZ\")\n",
    "    full_times.append((from_str, to_str))\n",
    "    dt += timedelta(minutes=30)\n",
    "\n",
    "# === DETERMINE FINAL COLUMN ORDER ===\n",
    "sorted_fuels = sorted(all_fuels)\n",
    "fieldnames = [\"from\", \"to\", \"regionid\", \"dnoregion\", \"forecast\", \"index\"] + sorted_fuels\n",
    "\n",
    "# === BUILD FINAL ROWS ===\n",
    "all_rows = []\n",
    "for from_str, to_str in full_times:\n",
    "    for regionid in sorted(all_regionids):\n",
    "        key = (from_str, regionid)\n",
    "        row = raw_data.get(key, {\n",
    "            \"from\": from_str,\n",
    "            \"to\": to_str,\n",
    "            \"regionid\": regionid,\n",
    "            \"dnoregion\": \"\",\n",
    "            \"forecast\": \"\",\n",
    "            \"index\": \"\"\n",
    "        })\n",
    "        for fuel in sorted_fuels:\n",
    "            row.setdefault(fuel, \"\")\n",
    "        all_rows.append(row)\n",
    "\n",
    "# === WRITE TO CSV ===\n",
    "with open(output_path, mode=\"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for row in all_rows:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f\"Saved combined CSV with filled gaps to: {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sef-python-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
